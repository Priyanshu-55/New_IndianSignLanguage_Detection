# New_IndianSignLanguage_Detection

#ğŸ‘ Indian Sign Language Detection ğŸ‡®ğŸ‡³
##ğŸ“œ Description
Indian Sign Language Detection is an ongoing project aimed at bridging the communication gap between specially-abled individuals and others by recognizing sign language gestures in real time.

##ğŸŒŸ Background
One of the major challenges faced by specially-abled individuals is effective communication with those who do not understand sign language. This project uses machine learning to detect and classify gestures, enabling smoother and more meaningful interactions.

##âœ¨ What's in it?
###ğŸ“‚ Dataset Creation:

Organized folders for each word in the sign language.
Recorded 180 videos for each word, capturing 30 frames per video.
Used MediaPipe to extract pose and hand landmarks separately and merged them for comprehensive data.
###ğŸ”§ Preprocessing:

Augmented data using techniques like scaling, mirroring, speed adjustments, and other methods to increase variability.
###ğŸ¤– Model Building:

Built an LSTM-based sequential model to analyze landmark sequences and predict gestures in real time.
###ğŸš€ Current Status
This is an ongoing project, with exciting features and improvements yet to come. Stay tuned!

#ğŸ¯ Future Plans
Enhance the dataset with additional gestures and real-world scenarios.
Integrate with a user-friendly interface for seamless interaction.
Optimize real-time detection speed and accuracy.
#ğŸ™Œ Contributions
We welcome contributions! If you have ideas to improve the project or want to fix a bug, feel free to create a pull request or open an issue.

ğŸ“§ Contact
For queries, reach out via: priyanshuy2005@gmail.com
